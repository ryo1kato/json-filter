#!/usr/bin/env python
#
# Dumb simple JSON accessor with dotdict notation support.
#
# Dotdict notation of "capacityList[0].capacity.hostName"
# is equivalent to "['capacityList'][0]['capacity']['hostName']" of Python
#

VERSION = (0,2)
USAGE = """\
%prog [OPTIONS] [FILENAME] [JSON_DITDICT]
%prog --csv [OPTIONS] [FILENAME] [JSON_DITDICT] [--cols=COL1,COL2,...]

DESCRIPTION
  Simple JSON analyzer and filter with dotdict notation + wildcard support.

COLUMNS
  Name or position of column for output CSV. Symbolic name if input is
  an array of dictionaries, or position number (starts from 1), if input
  is an array of arrays.

EXAMPLE
  '.name1.name2[999].name3' - full path
  '[0].name1.name2'         - if a top level object is an array.
  'name1.name2[999].name3'  - You can ommit proceeding '.'
  'name1.name2[*].name3'    - Array index wildcard (all items of array)
  'name1.name2.name3'       - Implecit list expansion - assume '[*]' is omitted.
 ('name1.name2[1,2,3-9]'    - index range is NOT IMPLEMENTED YET)
  'name1.*.name3'           - Wildcard '*'
 ('name1.na*2.name3'        - partial match is NOT IMPLEMENTED YET.)
  '{name1a,name1b}.name2'   - Expanded to 'name1a.name2' and 'name1a.name2'"""
#
# TODO
#   * Unit test
#   * Multiple subscript / range support for list (subscript_str)
#   * Partial match wildcard support
#   * Attribute conditions
#
# BUGS & KNOWN ISSUES
#   * Not good for big data; this script loads entire input into memory as
#     objects (using json.load() method), thus input must hit into
#     your machines' RAM.
#   * Nested arrays are not supported
#

##############################################################################
import os
import sys
import re
import optparse
import json

sys.tracebacklimit = 2

class OutFormat:
    Auto, Pretty, JSON, CSV = range(4)

##############################################################################

def is_number(obj):
    if isinstance(obj, int) or isinstance(obj, long) or isinstance(obj, float):
        return True
    else:
        return False


def is_rawtype(obj):
    return isinstance(obj, basestring) or is_number(obj)



##############################################################################
# "name" is shorthand for "TOP.name" or "TOP[*].name"
# "[99].name" is shorthand for "TOP[99].name"
# "name1.name2" is shorthand for "name1[*].name2" or even "name1[*].name2"
# when name1 and/or name2 is an array.


def debug(msg):
    #print "DEBUG: ", msg
    pass

def concat(mylist):
    return "".join(mylist)

class DotDictError(Exception):
    def __init__(self, msg=''):
        if isinstance(msg, list):
            self.msg = concat(msg)
        else:
            self.msg = msg
    def __str__(self):
        return self.msg.__str__()

class DotDictMalformed(DotDictError):  pass
class DotDictNoMatch(DotDictError): pass
class CSVConvertError(DotDictError): pass
class CSVInvalidColumn(DotDictError): pass

res = {
        "delim": "[\[\.]",
        "name":  "([A-Za-z]\w*|\*)",
        "index": "(?:\[(?P<index>\d+|\*)\])"
}
names = { "names": "%(name)s(%(delim)s.+)?" % res }
res['multi'] = "%(names)s(?:,%(names)s)*" % names

re_delim = re.compile("^%(delim)s"%res)
re_name  = re.compile("^\.%(name)s(?P<rest>%(delim)s.+)*$" % res)
re_index = re.compile("^%(index)s(?P<rest>%(delim)s.+)*$" % res)
re_multi = re.compile("^\.\{(?P<multi>%(multi)s)\}(?P<rest>%(delim)s.+)*$" % res)


def dotdictget(myjson, dotdict):
    """Wrapper for _dotdictget() to allow omiting topmost object/array index
    """
    if re_delim.match(dotdict):
        normalized_dotdict = dotdict
    else:
        normalized_dotdict = '.' + dotdict

    return _dotdictget(myjson, normalized_dotdict, [])


def _dotdictget(myjson, dotdict, traversed=[]):
    debug("dotdict: %s/%s"%("".join(traversed), dotdict or "$"))
    if not dotdict or dotdict == '':
        debug("    Leaf: " + ''.join(traversed))
        return (myjson, [myjson])
    else:
        m_name  = re_name.match(dotdict)
        m_index = re_index.match(dotdict)
        m_multi = re_multi.match(dotdict)
        if m_name:
            if isinstance(myjson,list):
                return _dotdictget_list(myjson, '*', dotdict, traversed)
            else:
                name = m_name.group(1)
                rest = m_name.group('rest')
                return _dotdictget_dict(myjson, name, rest, traversed)

        elif m_index:
            index_s = m_index.group(1)
            rest  = m_index.group('rest')
            return _dotdictget_list(myjson, index_s, rest, traversed)

        elif m_multi:
            if isinstance(myjson,list):
                return _dotdictget_list(myjson, '*', dotdict, traversed)
            else:
                # aggregator
                multi = m_multi.group('multi').split(',')
                rest  = m_multi.group('rest') or ""
                multi_expanded = {}
                leaves = []
                for path in multi:
                    newpath = "." + path + rest
                    debug("NEWPATH: %s/%s"%("".join(traversed),newpath))
                    (ret, leaf) = _dotdictget(myjson, newpath, traversed)
                    multi_expanded.update( ret )
                    leaves.extend( leaf )
                return (multi_expanded, leaves)

        else:
            raise DotDictMalformed(dotdict)


def _dotdictget_dict(mydict, name, rest, traversed=[]):
    trace = traversed + ["."+name]
    if not isinstance(mydict,dict):
        raise DotDictNoMatch(trace)

    try:
        if name == '*':
            # aggregator
            wildcard_expanded = {}
            leaves = []
            for n in mydict.keys():
                try:
                    subtree, leaf = _dotdictget(mydict[n], rest, trace)
                    wildcard_expanded[n] = subtree
                    leaves.extend( leaf )
                except DotDictNoMatch:
                    pass
            if wildcard_expanded:
                return (wildcard_expanded, leaves)
            else:
                raise DotDictNoMatch(concat(trace) + rest)
        else:
            subtree, leaf = _dotdictget(mydict[name], rest, trace)
            return ({name: subtree}, leaf)
    except KeyError:
        raise DotDictNoMatch(trace)


def _dotdictget_list(mylist, index_s, rest, traversed=[]):
    trace = traversed+["[%s]"%index_s]
    if isinstance(mylist,list):
        if index_s == '*':
            list_expanded = []
            leaves = []
            for j in mylist:
                try:
                    (subtree, leaf) = _dotdictget(j, rest, trace)
                    list_expanded.append( subtree )
                    leaves.extend( leaf )
                except DotDictNoMatch:
                    pass
            if list_expanded:
                return (list_expanded, leaves)
            else:
                raise DotDictNoMatch(trace)
        else:
            index = int(index_s)
            try:
                subtree, leaf = _dotdictget(mylist[index], rest, trace)
                return ([subtree], leaf)
            except IndexError:
                raise DotDictNoMatch(trace)
    else:
        raise DotDictNoMatch(trace)


##############################################################################

def _escape_csv_cell(item, onError=None):
    """if an item is composite object, throw error,
    return a dummy value or empty string.
    """
    if is_rawtype(item):
        return item
    elif onError:
        if isinstance(onError, basestring):
            return onError
        elif hasattr(onError,'__call__'):
            return onError(item)
        else:
            return ''
    else:
        raise CSVConvertError(str(item))


def _get_cells(row, indices_or_keys, escape):
    """convert row, as list or dict, into list of 'cells' for CSV.
    if escape is not None, apply _escape_csv_cell()"""
    cells = []
    if indices_or_keys:
        for ik in indices_or_keys:
            try:
                if escape:
                    cells.append( _escape_csv_cell(row[ik], escape) )
                elif is_rawtype(row[ik]):
                    cells.append(row[ik])
                else:
                    msg = "cannot convert to value: %s"%str(row[ik])
                    raise CSVConvertError(msg)
            except (IndexError, KeyError):
                if escape:
                    cells.append( _escape_csv_cell(None, escape) )
                else:
                    if isinstance(ik,int):
                        msg = "invalid key or index: '%d'"%(ik+1)
                    else:
                        msg = "invalid key or index: '%s'"%ik
                    raise CSVConvertError(msg)

    elif isinstance(row,list):
        if escape:
            cells = [ _escape_csv_cell(cel, escape) for cel in row ]
        else:
            cells = row

    else:
        # _get_cells() must always be called with keys (indices_or_keys)
        # if row is an instance of dict
        raise CSVConvertError("Internal Error in _get_cells()")

    return [str(cel) for cel in cells]


def _print_csv_list(myListList, outfile, colIndices, escape):
    """print a row of a CSV file which is an instance of list.
    """
    nrRow = 0
    for row in myListList:
        cells = []
        nrRow += 1
        if isinstance(row, list):
            cells = _get_cells(row, colIndices, escape)
            outfile.write(",".join(cells) + '\n')
        else:
            msg = "Row %d: Cannot convert composit object to CSV: %s" \
                % (nrRow, row)
            raise CSVConvertError("msg")



def _print_csv_dict(myDictList, outfile,
                    colNames=None, header=True, escape=True):
    nrRow = 0
    if not colNames:
        colNames = myDictList[0].keys()
    if header:
        outfile.write(",".join(colNames) + '\n')

    for row in myDictList:
        nrRow += 1
        if isinstance(row, dict):
            cells = _get_cells(row, colNames, escape)
            outfile.write(",".join(cells) + '\n')
        else:
            msg = "Row %d: Cannot convert composit object to CSV: %s" \
                % (nrRow, row)
            raise CSVConvertError("Cannot convert composit object to CSV")


def _print_csv(mylist, outfile, columns, header=True, escape=True):
    if isinstance(mylist[0], list):
        colIndices = []
        for i in columns or []:
            try:
                colIndices.append(int(i)-1)
            except ValueError:
                raise CSVInvalidColumn("Invalid column number for array: %s"%i)
        _print_csv_list(mylist, outfile, colIndices, escape)
    elif isinstance(mylist[0], dict):
        colNames = columns or mylist[0].keys()
        _print_csv_dict(mylist, outfile, colNames, header, escape)
    else:
        msg = "the 1st row is not a list nor a dict: %s"%mylist[0]
        raise DotDictNoMatch(msg)


def print_csv(mylist, outfile, columns=None, header=True, escape=True):
    """Wrapper for _print_csv(): if mylist contains
    only one element, recurse into it.
    """
    if isinstance(mylist, list):
        if len(mylist) == 1:
            print_csv(mylist[0], outfile, columns, header, escape)
        else:
            _print_csv(mylist, outfile, columns, header, escape)
    elif isinstance(mylist,dict) and len(mylist) == 1:
        print_csv(mylist.values()[0], outfile, columns, header, escape)
    else:
        raise CSVConvertError("Cannot convert non-list data to CSV")




##############################################################################

def print_json_pretty(obj, force=False):
    """If obj is simply an array or raw data type, or a dict with
    only key-value pair in it, print as text.
    Otherwise dump it as JSON.
    """
    def recurse(subobj, force):
        # if the obj is array with one element / dict with one key, try to
        # pretty-print the inner obj.
        # FIXME: is it for 'single1.single2_3.single3_3'
        if print_json_pretty(subobj, force=True):
            return True
        else:
            if force:
                return False
            else:
                print json.dumps(obj, indent=4)
                return True

    if is_rawtype(obj):
        print obj
        return True
    elif isinstance(obj, list):
        if all([ is_rawtype(i) for i in obj ]):
            for item in obj:
                print item
            return True
        elif len(obj) == 1:
            return recurse( obj[0], force )
        elif all([ isinstance(i, dict) and len(i.keys()) == 1 and is_rawtype(i.values()[0])
                 for i in obj ]):
            for one_item_dict in obj:
                print one_item_dict.values()[0]
            return True
        elif force:
            # failed to pretty-print the object and need to back-track
            return False
        else:
            print json.dumps(obj, indent=4)
            return True
    elif isinstance(obj, dict) and len(obj.keys()) == 1:
        return recurse( obj.values()[0], force )
    elif force:
        return False
    else:
        print json.dumps(obj, indent=4)
        return True



##############################################################################
def DIE(msg):
    sys.stderr.write("ERROR: %s\n"%msg)
    sys.exit(1)

def myoptparse(argv):
    ## Option Parser
    parser = optparse.OptionParser(
        usage=USAGE,
        version=("%%prog %d.%d" % VERSION) )
    parser.add_option("-a", "--auto",
        action="store_const", dest="outformat", const=OutFormat.Auto,
        help="Text output for simple data structure, JSON otherwise")
    parser.add_option("-p", "--pretty",
        action="store_const", dest="outformat", const=OutFormat.Pretty,
        help="Simple text output for list-like data structure" +
             "(exit with error if input has complex data structure")
    parser.add_option("-c", "--csv",
        action="store_const", dest="outformat", const=OutFormat.CSV,
        help="Try to output in CSV format (table like data structure only).")
    parser.add_option("-j", "--json",
        action="store_const", dest="outformat", const=OutFormat.JSON,
        help="Always output in JSON format")
    parser.add_option("-C","--cols", dest="columns",
        help="(with --csv) output only selected columns" +\
             "sparated by commna(',')", metavar="COL1,COL2,...")
    parser.add_option("-H", "--no-csv-header", dest='header',
        action="store_false", default=True,
        help="Print header for Comma Separated Value output.")
    parser.add_option("-i","--ignore", dest="escape",
        action="store_true", default=False,
        help="(with --csv) Ignore error to convert CSV" +\
             "and do not attempt to normalize data(like escape ',' in data)")
    parser.add_option("-l","--leaves", dest="leaf",
        action="store_true", default=False,
        help="output leaf nodes filtered by dotdit, instead of root")
    parser.add_option("-v","--verbose",
        action="store_true", default=False,
        help="Verbose output")

    (opt, args) = parser.parse_args(argv)
    return (opt, args)


def json_filter(args):
    infile  = sys.stdin
    dotdict = None
    if len(args) == 0:
        pass
    elif len(args) == 1:
        if os.path.exists(args[0]):
            infile  = open(args[0])
        else:
            dotdict = args[0]
    elif len(args) == 2:
        infile  = open(args[0])
        dotdict = args[1]
    else:
        DIE("Too many (%d) arguments\n"%len(args))

    try:
        inputjson = json.load(infile)
    except ValueError as e:
        DIE(str(e))

    if dotdict:
        try:
            (myjson, leaves) = dotdictget( inputjson, dotdict )
        except DotDictNoMatch as e:
            sys.stderr.write("No matching object found for '%s'\n"%e)
            sys.exit(1)
        except DotDictMalformed as e:
            DIE("Malformed DotDict notation: '%s' in '%s'\n" %(e, dotdict))
    else:
        myjson = inputjson
        leaves = [ myjson ]

    if dotdict and len(myjson) == 0:
         DIE("No matching JSON attribute found in the input")

    return (myjson, leaves, dotdict)


def main():
    try:
        (opt, args) = myoptparse(sys.argv[1:])
        (myjson, leaves, dotdict) = json_filter(args)

        if opt.leaf:
            if len(leaves) == 1:
                outjson = leaves[0]
            else:
                outjson = leaves
        else:
            outjson = myjson

        if opt.outformat == OutFormat.CSV:
            columns = opt.columns and opt.columns.split(',')
            try:
                print_csv(outjson, sys.stdout, columns,
                          header=opt.header, escape=opt.escape)
                sys.exit(0)
            except (CSVConvertError, CSVInvalidColumn) as e:
                DIE(e)
        elif opt.outformat == OutFormat.JSON:
            print json.dumps(outjson, indent=4)
            sys.exit(0)
        elif opt.outformat == OutFormat.Pretty:
            if print_json_pretty(outjson, force=True):
                pass
            else:
                DIE("Too complex data for '--pretty' output")
        else:
            print_json_pretty(outjson)
            sys.exit(0)

    except KeyboardInterrupt:
        sys.exit(1)

    except Exception as e:
        if opt.verbose:
            raise
        else:
            DIE("Unhandled Internal Error: %s"%str(e))


if __name__ == "__main__":
    main()
